<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Josiah Parry">

<title>Predicting to New Locations in Spatial ML</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="README_files/libs/clipboard/clipboard.min.js"></script>
<script src="README_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="README_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="README_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="README_files/libs/quarto-html/popper.min.js"></script>
<script src="README_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="README_files/libs/quarto-html/anchor.min.js"></script>
<link href="README_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="README_files/libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="README_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="README_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="README_files/libs/bootstrap/bootstrap-d6a003b94517c951b2d65075d42fb01b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Predicting to New Locations in Spatial ML</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Josiah Parry <a href="mailto:jparry@esri.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> <a href="https://orcid.org/0000-0003-1689-0557" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Esri
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  


</header>


<section id="problem-statement" class="level2">
<h2 class="anchored" data-anchor-id="problem-statement">Problem Statement</h2>
<p>Predicting to new locations in spatially explicit machine learning models is ill-defined. These models use spatially lagged covariates, or message passing in the case of graph neural networks (GNNs), which are defined only for locations embedded in the training spatial weights matrix (SWM). Prediction requires both identifying the neighborhood structure of new locations and accessing the covariate values used to construct the lag. Without this information, the required inputs do not exist.</p>
</section>
<section id="spatially-explicit-model-approaches" class="level2">
<h2 class="anchored" data-anchor-id="spatially-explicit-model-approaches">Spatially Explicit Model Approaches</h2>
<p>Models become spatially explicit through various mechanisms. The following approaches incorporate spatial relationships into machine learning models:</p>
<ul>
<li><strong>Spatial lags</strong>: Weighted averages of neighbor values in spatial regression models</li>
<li><strong>Message passing</strong>: Graph neural network mechanism equivalent to spatial lags on hidden dimensions</li>
<li><strong>Moran Eigenvector Maps (MEMs)</strong>: Spatial features derived from the spatial weights matrix</li>
<li><strong>Geographically Weighted Regression (GWR/MGWR)</strong>: Local regression coefficients estimated at each location</li>
<li><strong>Distance features</strong>: Covariates computed relative to external reference layers</li>
<li><strong>Spatial indexing</strong>: H3, S2, or geohashes as categorical features (unproblematic for prediction)</li>
<li><strong>Coordinates and regimes</strong>: X/Y coordinates or spatial regimes as features (unproblematic for prediction)</li>
</ul>
<p>For simplicity, we focus on <strong>spatial lags</strong> as the canonical spatially explicit feature, though the challenges discussed apply broadly to approaches dependent on the spatial weights matrix or training data. At the end we discuss how these challenges extend to other approaches.</p>
</section>
<section id="spatially-explicit-model-prediction-scenarios" class="level2">
<h2 class="anchored" data-anchor-id="spatially-explicit-model-prediction-scenarios">Spatially Explicit Model Prediction Scenarios</h2>
<p>Consider a model trained on a study area with a spatial lag of variable <span class="math inline">\(X_1\)</span>. Four prediction scenarios emerge:</p>
<p><strong>1. Prediction at all original locations with updated covariates</strong>: Use the same adjacency matrix; calculate spatial lag from new <span class="math inline">\(X_1\)</span> values for all locations. Requires persisting or recreating the SWM and collecting new data for all locations.</p>
<p><strong>2. Prediction at a single original location</strong>: Use known adjacency; calculate lag from training data. Requires persisting the SWM and original <span class="math inline">\(X_1\)</span> values.</p>
<p><strong>3. Prediction at an entirely new study area</strong>: Create a new SWM for the new region; calculate spatial lag from new data. Raises questions about adjacency structure consistency (e.g., must k-NN be used if trained on k-NN?).</p>
<p><strong>4. Prediction at m new locations within the original study area</strong>: Most complex scenario—requires choosing how new locations relate to the training graph (see Approaches to Spatial Feature Construction below).</p>
<p><strong>Graph Neural Networks</strong>: GNNs face similar challenges. Transductive models cannot generalize to unseen nodes. Inductive models can generalize but still require graph structure for new nodes, necessitating insertion into or reconstruction of the adjacency matrix.</p>
</section>
<section id="approaches-to-spatial-feature-construction" class="level2">
<h2 class="anchored" data-anchor-id="approaches-to-spatial-feature-construction">Approaches to Spatial Feature Construction</h2>
<p>When confronting the train/test boundary, three coherent positions exist:</p>
<p><strong>A. Closed system (transductive)</strong>: Calculate spatial lag on the full dataset (train + test) before splitting. Semantically consistent but implies leakage and undefined prediction to new locations.</p>
<p><strong>B. Fully separate graphs</strong>: Lags computed independently within training and test sets. Semantically consistent but model is evaluated on a different graph structure than it was trained on.</p>
<p><strong>C. Hybrid approaches</strong>: Test lags incorporate training data. Two variants:</p>
<ul>
<li><strong>C1 (Individual lookup)</strong>: Each test point finds neighbors in the training set independently; test points do not see each other.</li>
<li><strong>C2 (Grow adjacency matrix)</strong>: Combine training and test points into a new adjacency matrix where test points can neighbor each other and training points.</li>
</ul>
<p>None of these approaches is obviously correct. Each involves trade-offs between semantic consistency, data leakage, and the ability to predict at new locations. The common practice (Position A) works for in-sample evaluation but leaves prediction to new locations undefined. Position C variants enable prediction but introduce semantic inconsistency—the model learns relationships among training neighbors but predicts using different neighbor definitions.</p>
</section>
<section id="examples-from-literature" class="level2">
<h2 class="anchored" data-anchor-id="examples-from-literature">Examples from Literature</h2>
<p><strong>Position A in practice <span class="citation" data-cites="Liu2022-pv">(<a href="#ref-Liu2022-pv" role="doc-biblioref">Liu, Kounadi, and Zurita-Milla 2022</a>)</span></strong>: Compute spatial lags on the full dataset before partitioning for cross-validation. This is common practice—works for in-sample evaluation but leaves prediction to new locations undefined.</p>
<p><strong>Position C1 in practice <span class="citation" data-cites="sarf2025">(<a href="#ref-sarf2025" role="doc-biblioref">Credit 2025</a>)</span></strong>: The <code>{sarf}</code> package’s <code>spatial_cv_rf()</code> function finds neighbors in the training set for each test observation independently. Test points do not see each other, even if spatially adjacent.</p>
<p><strong>Position C1 with explicit prediction <span class="citation" data-cites="Gao2025-mgwxgb">(<a href="#ref-Gao2025-mgwxgb" role="doc-biblioref">Gao, He, and Kwan 2025</a>)</span></strong>: M-GWXGB explicitly implements prediction to new locations by finding k-nearest training locations and averaging their local model predictions. This requires persisting all local models, training locations, and bandwidth—the model alone cannot predict.</p>
</section>
<section id="challenges-for-prediction" class="level2">
<h2 class="anchored" data-anchor-id="challenges-for-prediction">Challenges for Prediction</h2>
<p>Three core challenges emerge across prediction scenarios:</p>
<p><strong>1. Modifying the Adjacency Matrix</strong>: New locations require insertion into or reconstruction of the SWM. For GNNs, new prediction points must be identified relative to the original adjacency matrix. The choice between insertion (preserving training structure) versus recomputation (rebuilding from scratch) involves trade-offs between consistency with training and spatial coherence of predictions.</p>
<p><strong>2. Feature Construction</strong>: Spatial lags for new locations require covariate values from neighbors. This raises the question: how do we determine which features are neighbors of the new prediction point? Those neighbors may be training observations, new observations, or both—corresponding to the positions outlined above.</p>
<p><strong>3. Storing the Adjacency Matrix and Training Features</strong>: Both adjacency modification and feature construction require access to the original SWM and covariate values. These must be persisted beyond training—not typically part of standard ML model serialization. For methods like GWR/MGWR, the entire training dataset must be stored alongside the model.</p>
<p>The literature largely overlooks these challenges. Papers focus on model training but do not account for predicting to <strong>new locations</strong>. This creates a gap between methodological innovation and operational deployment. Prediction at new locations is not a trivial extension of training—it requires explicit protocols for SWM persistence, adjacency decisions at prediction time, and covariate availability.</p>
<hr>
</section>
<section id="detailed-outline" class="level2">
<h2 class="anchored" data-anchor-id="detailed-outline">Detailed Outline</h2>
<section id="current-practice-and-its-implicit-assumptions" class="level3">
<h3 class="anchored" data-anchor-id="current-practice-and-its-implicit-assumptions">Current Practice and Its Implicit Assumptions</h3>
<ul>
<li>Standard workflow: calculate spatial lag (or other spatially derived features) on the full dataset, then partition into train/test/validation sets for spatial CV</li>
<li>This approach has a transductive character—test observations are embedded in the spatial graph from the start</li>
<li>The spatial lag of a test observation was computed using training observations (and vice versa)</li>
<li>The test set was never truly “held out”—it participated in feature construction</li>
<li>Spatial CV is presented as rigorous, but if features are computed on the full graph before splitting, what is actually being validated?</li>
<li>This workflow implicitly assumes a closed system where all locations are known at training time</li>
<li>Prediction to genuinely new locations is undefined because the workflow was never designed for it</li>
</ul>
</section>
<section id="three-positions-on-spatial-feature-construction-detailed" class="level3">
<h3 class="anchored" data-anchor-id="three-positions-on-spatial-feature-construction-detailed">Three Positions on Spatial Feature Construction (Detailed)</h3>
<p>When confronting the train/test boundary, three coherent positions exist. For illustration, assume we use <span class="math inline">\(k\)</span>-nearest neighbors (kNN) as the method of defining adjacency, though the logic applies to other adjacency definitions.</p>
<p><strong>A. Closed system (transductive)</strong></p>
<ul>
<li>Calculate spatial lag on the full dataset (train + test) before splitting</li>
<li>Semantically consistent—lag means the same thing for all observations</li>
<li>Implies: leakage; test set must be known at training time; prediction to new locations undefined</li>
</ul>
<p><strong>B. Fully separate graphs</strong></p>
<ul>
<li>Training: lags computed among training points only</li>
<li>Testing: lags computed among test points only (neighbors are other test points)</li>
<li>Semantically consistent—lag always means “average among my peers”</li>
<li>Implies: model is evaluated on a different graph structure than it was trained on</li>
</ul>
<p><strong>C. Hybrid approaches (test lags incorporate training data)</strong></p>
<p>Two variants exist:</p>
<ul>
<li><strong>C1: Individual lookup</strong> — Each test point finds its neighbors in the training set independently. Test points do not see each other. The adjacency matrix is not grown; test points query against it.</li>
<li><strong>C2: Grow the adjacency matrix</strong> — Combine test and training points into a new adjacency matrix. Test points can be neighbors of each other <em>and</em> of training points. Lags are computed on this combined structure.</li>
</ul>
<p>Both variants change the meaning of the spatial lag between training and testing. C1 treats each prediction as an isolated query; C2 treats the test set as a cohort integrated into the spatial structure.</p>
<p><em>Note</em>: None of these approaches is obviously correct. Each involves trade-offs between semantic consistency, data leakage, and the ability to predict at new locations. These positions directly inform the adjacency decisions discussed in the prediction scenarios below.</p>
</section>
<section id="the-semantic-inconsistency-of-position-c" class="level3">
<h3 class="anchored" data-anchor-id="the-semantic-inconsistency-of-position-c">The Semantic Inconsistency of Position C</h3>
<ul>
<li>During training, the spatial lag for observation <span class="math inline">\(i\)</span> is the (weighted) mean of <span class="math inline">\(Y\)</span> among <span class="math inline">\(i\)</span>’s neighbors—all of whom are in the training set</li>
<li>Under Position C1, the spatial lag for test observation <span class="math inline">\(j\)</span> is the mean of <span class="math inline">\(Y\)</span> among <span class="math inline">\(j\)</span>’s neighbors <em>in the training set</em>—the test point is querying a dataset it does not belong to</li>
<li>Under Position C2, the adjacency matrix is recalculated to include both training and test observations; test points can be neighbors of each other and of training points</li>
<li>The model learns “when my neighbors have high <span class="math inline">\(Y\)</span>, I tend to have high <span class="math inline">\(Y\)</span>”—but for test points under C1, “neighbors” means “nearest training observations”</li>
</ul>
</section>
<section id="detailed-approaches-by-type" class="level3">
<h3 class="anchored" data-anchor-id="detailed-approaches-by-type">Detailed Approaches by Type</h3>
<p><strong>Approaches Unproblematic for Prediction</strong></p>
<ul>
<li>Including X &amp; Y coordinates in a model—not ideal, but not problematic for prediction
<ul>
<li>Doesn’t incorporate relationship of feature and neighborhood</li>
</ul></li>
<li>Using H3 indexes, S2 indexes, or geohashes as categorical features
<ul>
<li>H3 recommends using <code>kRing</code> for spatial “convolution” (just a spatial lag) https://h3geo.org/docs/highlights/ml/</li>
<li>H3 interpolation in “Geographic Data Science with Python” https://geographicdata.science/book/notebooks/12_feature_engineering.html</li>
<li>https://www.analyticsvidhya.com/blog/2025/03/ubers-h3-for-spatial-indexing/#h-combining-h3-with-machine-learning</li>
</ul></li>
<li>Spatial regimes (e.g.&nbsp;state names) as categorical features</li>
</ul>
<p><em>Note</em>: These approaches allow prediction at new locations provided the index or regime can be assigned.</p>
<p><strong>Explanatory Distance Features</strong></p>
<ul>
<li>Distance features are computed relative to external reference layers</li>
<li>The model alone cannot predict—it requires the model plus the distance feature layers (supplementary data)</li>
<li>This raises the same structural questions as spatial lag models:
<ul>
<li>Must the distance feature layers be identical to those used during training?</li>
<li>Can we use new/matched distance feature layers for a different study area? When is this valid?</li>
<li>Can distance feature layers grow (training layers + new layers)?</li>
</ul></li>
<li>The choice of how to handle distance features at prediction time parallels the adjacency choices for spatial lag models</li>
</ul>
<p><strong>Approaches Dependent on the SWM</strong></p>
<ul>
<li>A spatial weights matrix is an n×n sparse square matrix. Non-zero values indicate the presence of a neighbor. By default, these are binary matrices where 1 indicates a neighbor. In this case a SWM is an adjacency matrix.</li>
<li>Models use spatial lags in the case of spatial regression (Anselin and Rey)</li>
<li>Include Moran Eigenvector Maps (MEMs) which are derived from the SWM (Dray)
<ul>
<li>Cannot be used on new locations</li>
</ul></li>
<li>Graph neural nets—a growing way of explicitly incorporating space—use “message passing” which is equivalent to a spatial lag except on hidden dimensions</li>
</ul>
<p><em>Note</em>: These approaches bind the model to a fixed neighborhood structure and create the prediction problem.</p>
<p><strong>Approaches Dependent on Training Data at Prediction Time</strong></p>
<ul>
<li>Geographically Weighted Regression (GWR) and Multiscale GWR (MGWR) do not use a SWM, but face analogous prediction challenges</li>
<li>GWR fits local regression coefficients at each training location using distance-weighted observations</li>
<li>The “model” is not a single set of coefficients—it is <span class="math inline">\(n\)</span> sets of local coefficients, one per training location</li>
<li>To predict at a new location, coefficients must be estimated <em>at that location</em> by fitting a new weighted regression using nearby training observations</li>
<li>This requires access to training <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> at prediction time, not just a saved model object</li>
<li>MGWR adds complexity: each covariate has its own bandwidth, requiring multiple local regressions at each new prediction point</li>
<li>The bandwidth(s) learned during training can be reused, but the local coefficient estimation still requires training data</li>
</ul>
<p><em>Note</em>: GWR/MGWR cannot escape the same fundamental issue—prediction requires access to training data, not just a serialized model. The “train once, predict anywhere” paradigm does not apply.</p>
</section>
<section id="detailed-prediction-scenarios" class="level3">
<h3 class="anchored" data-anchor-id="detailed-prediction-scenarios">Detailed Prediction Scenarios</h3>
<p><strong>Prediction Scenarios: Spatial Lag Models</strong></p>
<p>Model was trained on a study area with a spatial lag of variable <span class="math inline">\(X_1\)</span>.</p>
<p><strong>Prediction at All Original Locations with Updated Covariates</strong></p>
<p>We want to predict for all of the same locations we trained on, but with new covariate values collected post-training. We can use the same adjacency matrix and calculate the spatial lag of <span class="math inline">\(X_1\)</span> using new data for all locations.</p>
<ul>
<li>We can either persist the SWM or recreate it</li>
<li>Requires new <span class="math inline">\(X_1\)</span> for all locations</li>
</ul>
<p><strong>Prediction at a Single Original Location</strong></p>
<p>We want to predict to a single location in the original training set. We know the adjacency for this location. We can calculate lag of <span class="math inline">\(X_1\)</span> from training data and use that as lag of <span class="math inline">\(X_1\)</span>.</p>
<ul>
<li>Requires we persist the SWM</li>
<li>Requires we persist the original <span class="math inline">\(X_1\)</span> for all locations so we can derive lag of <span class="math inline">\(X_{1i}\)</span> at a later point</li>
</ul>
<p><strong>Prediction at an Entirely New Study Area</strong></p>
<p>We want to predict to an entirely new study area using the same model. We must calculate lag of <span class="math inline">\(X_1\)</span> using our new data. We are responsible for creating a new SWM based on the input data.</p>
<ul>
<li>We must create a new SWM on the new data—raises questions about how we define adjacency for the new data. Must it be the same adjacency structure—e.g.&nbsp;trained on k-NN predicted to k-NN?</li>
<li>Requires that we calculate lag of <span class="math inline">\(X_1\)</span> from <span class="math inline">\(X_1\)</span> of all new locations</li>
</ul>
<p><strong>Prediction at m New Locations Within the Original Study Area</strong></p>
<p>We want to predict <span class="math inline">\(m\)</span> new locations that are part of the study region. This is where the positions defined in “Three Positions on Spatial Feature Construction” become operationally relevant:</p>
<ul>
<li><strong>Position B</strong>: Adjacency defined only among the new prediction set, ignoring the training graph</li>
<li><strong>Position C1</strong>: Each new point finds neighbors in the original SWM only; new points do not see each other</li>
<li><strong>Position C2</strong>: Grow the adjacency matrix to include both original and new locations; new points can be neighbors of each other and of training points</li>
</ul>
<p>In all scenarios this requires:</p>
<ul>
<li>We persist the original SWM</li>
<li>We persist the original <span class="math inline">\(X_1\)</span> for all locations</li>
<li>If the SWM is grown (Position C2), we must augment the SWM and persist it, same with <span class="math inline">\(X_1\)</span> data</li>
</ul>
<p><strong>Prediction Scenarios: Graph Neural Networks</strong></p>
<p><strong>Transductive vs.&nbsp;Inductive Models</strong></p>
<ul>
<li>Transductive: Fixed graph; cannot generalize to unseen nodes</li>
<li>Inductive: Can generalize, but still requires graph structure for new nodes</li>
</ul>
<p>TODO: discuss transductive vs inductive models in more detail</p>
<p><strong>Prediction Mechanics</strong></p>
<p>When we consider GNNs these same points are the same/similar. However, we cannot necessarily predict to new locations unless using an inductive model. In order to predict with a GNN, the full adjacency matrix and X matrix must be provided. So, in order to do this, we must insert new points into the trained adjacency matrix. This thus requires us to address the same problems as spatial lag models.</p>
</section>
<section id="literature-examples-detailed" class="level3">
<h3 class="anchored" data-anchor-id="literature-examples-detailed">Literature Examples (Detailed)</h3>
<p><strong>Position A in practice: <span class="citation" data-cites="Liu2022-pv">Liu, Kounadi, and Zurita-Milla (<a href="#ref-Liu2022-pv" role="doc-biblioref">2022</a>)</span></strong></p>
<p><span class="citation" data-cites="Liu2022-pv">Liu, Kounadi, and Zurita-Milla (<a href="#ref-Liu2022-pv" role="doc-biblioref">2022</a>)</span> compute spatial lags on the full dataset before partitioning for cross-validation. This is Position A—the standard practice. It works for in-sample evaluation but leaves prediction to new locations undefined.</p>
<p><strong>Position C1 in practice: <span class="citation" data-cites="sarf2025">Credit (<a href="#ref-sarf2025" role="doc-biblioref">2025</a>)</span></strong></p>
<p>The <code>{sarf}</code> package’s <code>spatial_cv_rf()</code> function implements Position C1 (see https://github.com/kcredit/SArf/blob/58b26a4e4be43b3ddf2dbee08e38b86066b40c96/R/spatial_cv.R#L16). For each test observation, it finds neighbors in the training set and computes the lag from training <span class="math inline">\(Y\)</span> values. Each test point is treated as an isolated query against the training graph. Test points do not see each other—even if two test points are spatially adjacent, they cannot be neighbors.</p>
<p><strong>Position C1 with explicit prediction: <span class="citation" data-cites="Gao2025-mgwxgb">Gao, He, and Kwan (<a href="#ref-Gao2025-mgwxgb" role="doc-biblioref">2025</a>)</span></strong></p>
<p>M-GWXGB is notable for explicitly implementing prediction to new locations. The <code>GeoWeightedXGBoostPredictor</code> class predicts at new locations by finding the k-nearest training locations, retrieving those locations’ models, and averaging their predictions (see https://github.com/yiloufengyue/M-GWXGB/blob/main/M_GWXGB_1.py). This requires persisting all local models, training locations, and the bandwidth. The model alone cannot predict—it requires the full training infrastructure.</p>

</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-sarf2025" class="csl-entry" role="listitem">
Credit, Kevin. 2025. <span>“<span>SArf</span>: Spatial Autoregressive Random Forest.”</span> <a href="https://github.com/kcredit/SArf">https://github.com/kcredit/SArf</a>.
</div>
<div id="ref-Gao2025-mgwxgb" class="csl-entry" role="listitem">
Gao, Fan, Sylvia Y. He, and Mei-Po Kwan. 2025. <span>“Mixed Geographically Weighted <span>XGBoost</span> (<span>M-GWXGB</span>) Model: A New Spatially Explicit Machine Learning Model.”</span> <em>Annals of the American Association of Geographers</em>, December, 1–32. <a href="https://doi.org/10.1080/24694452.2025.2586039">https://doi.org/10.1080/24694452.2025.2586039</a>.
</div>
<div id="ref-Liu2022-pv" class="csl-entry" role="listitem">
Liu, Xiaojian, Ourania Kounadi, and Raul Zurita-Milla. 2022. <span>“Incorporating Spatial Autocorrelation in Machine Learning Models Using Spatial Lag and Eigenvector Spatial Filtering Features.”</span> <em>ISPRS Int. J. Geoinf.</em> 11 (4): 242.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>